name: Download Latest WHO PDF

on:
  workflow_dispatch:
    inputs:
      week_number:
        description: 'Week number to download (leave empty for latest)'
        required: false
        type: string
        default: ''
      upload_to_blob:
        description: 'Upload to Azure blob storage'
        required: false
        type: boolean
        default: false
  schedule:
    - cron: '47 13 * * 2,5'

jobs:
  download-pdf:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true

      - name: Install system dependencies
        run: |
          sudo apt-get update
          # Install Chrome instead of Chromium for better Selenium compatibility
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Install Python dependencies
        run: uv sync --frozen

      - name: Create output directory
        run: mkdir -p downloads

      - name: Download WHO PDF
        env:
          STAGE: dev
          DSCI_AZ_BLOB_DEV_SAS_WRITE: ${{ secrets.DSCI_AZ_BLOB_DEV_SAS_WRITE }}
        run: |
          # Always upload to blob for scheduled runs; manual runs can opt-in
          ARGS="--output-dir downloads --save-metadata downloads/metadata.json"

          if [ -n "${{ inputs.week_number }}" ]; then
            ARGS="$ARGS --week ${{ inputs.week_number }}"
            echo "Downloading week ${{ inputs.week_number }}..."
          else
            echo "Downloading latest week..."
            # For scheduled runs (no manual input), always upload
            if [ "${{ github.event_name }}" = "schedule" ]; then
              ARGS="$ARGS --upload"
            fi
          fi

          # Manual runs: respect the upload toggle
          if [ "${{ inputs.upload_to_blob }}" = "true" ]; then
            ARGS="$ARGS --upload"
          fi

          uv run python scripts/download_latest_who_pdf.py $ARGS

      - name: Display summary
        if: always()
        run: |
          echo "=== Download Summary ==="
          ls -lh downloads/*.pdf 2>/dev/null || echo "No PDFs found"

          if [ -f "downloads/metadata.json" ]; then
            echo ""
            echo "=== Bulletin Metadata ==="
            cat downloads/metadata.json | uv run python -m json.tool
          fi

      - name: Upload artifacts
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: who-cholera-pdf-${{ github.run_number }}
          path: downloads/
          retention-days: 90

      - name: Create job summary
        if: success()
        run: |
          # Check if metadata.json exists and what status it contains
          if [ -f "downloads/metadata.json" ]; then
            STATUS=$(uv run python -c "import json; print(json.load(open('downloads/metadata.json')).get('status', 'success'))" 2>/dev/null || echo "success")
            WEEK=$(uv run python -c "import json; print(json.load(open('downloads/metadata.json'))['week'])")
            YEAR=$(uv run python -c "import json; print(json.load(open('downloads/metadata.json'))['year'])")
            DATE_RANGE=$(uv run python -c "import json; print(json.load(open('downloads/metadata.json'))['date_range'])")

            # Different headers based on status
            if [ "$STATUS" = "already_exists" ]; then
              echo "## Already Up-to-Date âœ…" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "The latest bulletin already exists in blob storage. No download needed." >> $GITHUB_STEP_SUMMARY
            else
              echo "## Download Successful! âœ…" >> $GITHUB_STEP_SUMMARY
            fi

            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### Bulletin Details" >> $GITHUB_STEP_SUMMARY
            echo "- **Week**: $WEEK" >> $GITHUB_STEP_SUMMARY
            echo "- **Year**: $YEAR" >> $GITHUB_STEP_SUMMARY
            echo "- **Date Range**: $DATE_RANGE" >> $GITHUB_STEP_SUMMARY

            # Show downloaded file info only if we actually downloaded
            if [ "$STATUS" != "already_exists" ]; then
              PDF=$(ls downloads/*.pdf 2>/dev/null | head -1)
              if [ -f "$PDF" ]; then
                SIZE=$(du -h "$PDF" | cut -f1)
                NAME=$(basename "$PDF")
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "### Downloaded File" >> $GITHUB_STEP_SUMMARY
                echo "- **Filename**: \`$NAME\`" >> $GITHUB_STEP_SUMMARY
                echo "- **Size**: $SIZE" >> $GITHUB_STEP_SUMMARY
              fi

              if [ "${{ inputs.upload_to_blob }}" = "true" ] || [ "${{ github.event_name }}" = "schedule" ]; then
                echo "" >> $GITHUB_STEP_SUMMARY
                echo "### Blob Storage" >> $GITHUB_STEP_SUMMARY
                echo "â˜ï¸ PDF uploaded to Azure blob storage" >> $GITHUB_STEP_SUMMARY
              fi
            else
              # Already exists - show blob path
              BLOB_PATH=$(uv run python -c "import json; print(json.load(open('downloads/metadata.json'))['blob_path'])" 2>/dev/null || echo "N/A")
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "### Blob Storage" >> $GITHUB_STEP_SUMMARY
              echo "ðŸ“ Existing blob: \`$BLOB_PATH\`" >> $GITHUB_STEP_SUMMARY
            fi
          else
            # No metadata file - something went wrong or old behavior
            echo "## Download Successful! âœ…" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "âš ï¸ No metadata available" >> $GITHUB_STEP_SUMMARY
          fi
