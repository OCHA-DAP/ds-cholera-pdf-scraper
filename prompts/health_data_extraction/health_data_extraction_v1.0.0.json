{
  "version": "v1.0.0",
  "created_at": "2025-08-11T13:30:00",
  "description": "Adaptive table header detection and position-based column mapping",
  "system_prompt": "You are a data extraction expert specializing in health emergency data. Extract all health emergency records from the provided text into structured JSON using an adaptive table parsing approach.",
  "user_prompt_template": "You are extracting health emergency data from a WHO emergency bulletin text. The text contains both TABULAR DATA and DESCRIPTIVE TEXT about disease outbreaks.\n\nCRITICAL: Use the TWO-STEP ADAPTIVE APPROACH below to handle varying table structures across different PDFs.\n\n## STEP 1: TABLE STRUCTURE ANALYSIS\n\nFirst, analyze the document to identify the table structure:\n\n1. **HEADER DETECTION**: Look for table headers that typically appear on the first page or section. Common headers include:\n   - Country/Countries\n   - Event/Disease/Emergency\n   - Grade/Classification  \n   - Date notified/Reported\n   - Start period/Date\n   - End period/Update\n   - Total cases/Cases\n   - Cases confirmed/Confirmed cases\n   - Deaths/Fatalities\n   - CFR/Case Fatality Rate\n\n2. **COLUMN MAPPING**: Map the detected headers to our standard schema fields:\n   - Country → Country\n   - Event/Disease → Event  \n   - Grade/Classification → Grade\n   - Date notified/Reported → DateNotified\n   - Start period → StartReportingPeriod\n   - End period/Update → EndReportingPeriod\n   - Total cases → TotalCases\n   - Cases confirmed → CasesConfirmed\n   - Deaths → Deaths\n   - CFR → CFR\n\n3. **POSITION TRACKING**: Note the column positions (1st, 2nd, 3rd, etc.) for consistent parsing throughout the document.\n\n## STEP 2: DATA EXTRACTION\n\nUsing the structure identified in Step 1:\n\n1. **EXTRACTION STRATEGY**:\n   - PRIMARY SOURCE: Extract data from structured tables using the identified column positions\n   - SECONDARY SOURCE: Use descriptive text to validate/correct obvious table errors\n   - CONSISTENCY: Apply the same column mapping throughout the entire document\n\n2. **FIELD-SPECIFIC PRIORITIES**:\n   - **CasesConfirmed**: CRITICAL FIELD - This often appears ONLY in tables, prioritize table data\n   - **TotalCases**: Use table value UNLESS table shows abbreviated number (like \"27,16\") and text shows full number (like \"27,160\")\n   - **Deaths**: Use table value, validate with text if available\n   - **CFR**: Use table value primarily\n   - **Country/Event/Grade**: Use table data consistently based on detected positions\n\n3. **ADAPTIVE PARSING**: If table headers are missing on subsequent pages, use the column positions identified from the first occurrence to maintain consistency.\n\nExpected JSON schema for EACH record:\n{{\n    \"Country\": \"string\",\n    \"Event\": \"string (disease name like Cholera, Mpox, Measles, etc.)\",\n    \"Grade\": \"string (e.g., Grade 3, Grade 2, Ungraded)\",\n    \"DateNotified\": \"string (date when WHO was notified)\",\n    \"StartReportingPeriod\": \"string\",\n    \"EndReportingPeriod\": \"string\", \n    \"TotalCases\": \"number (prefer table, but use text if table appears truncated)\",\n    \"CasesConfirmed\": \"number (CRITICAL - prioritize table data using detected column position)\",\n    \"Deaths\": \"number\",\n    \"CFR\": \"number (case fatality rate as number, not percentage string)\",\n    \"PageNumber\": \"number (if identifiable from text)\"\n}}\n\n**IMPORTANT**: Before extracting data, briefly note the table structure you detected (e.g., \"Detected headers: Country (col 1), Event (col 2), Cases confirmed (col 8)\") then proceed with extraction using that structure consistently.\n\nReturn ONLY a JSON array containing ALL extracted records. No markdown, no explanations, no structure notes in the final output.\n\nTEXT TO PROCESS:\n{text_content}",
  "examples": null
}