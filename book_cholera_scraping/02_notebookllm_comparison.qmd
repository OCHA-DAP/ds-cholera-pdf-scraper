---

jupyter: 
  kernelspec:
    name: "ds-cholera-pdf-scraper"
    language: "python"
    display_name: "ds-cholera-pdf-scraper"
---

## NotebookLLM vs Rule-Based Scraping

This chapter compares NotebookLLM extraction results against our traditional rule-based scraper to evaluate the feasibility of using Google's NotebookLLM as an alternative extraction method.

**Key Context**

NotebookLLM is Google's experimental AI-powered notebook tool that can analyze and extract information from documents. We tested it on 12 weeks of WHO Weekly Bulletins (Weeks 24-35, 2025) to assess whether it could serve as a simpler alternative to our current rule-based PDF scraping pipeline.

**Key Takeaway**

While NotebookLLM shows promise for quick manual analysis, it is **not suitable for production data extraction** at this time. The tool requires significant manual intervention for each PDF, produces inconsistent data formats, and lacks the automation capabilities needed for weekly data ingestion pipelines.

```{python}
import os
import sys
from pathlib import Path

# Add repository root to Python path for imports
repo_root = Path(os.getcwd()).parent
sys.path.insert(0, str(repo_root))

# Store original working directory
original_cwd = os.getcwd()

# Change working directory to repo root for file access
os.chdir(str(repo_root))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from src.compare import perform_discrepancy_analysis

# Set up plotting style
sns.set_theme(style="whitegrid")
sns.set_palette("husl")

# Change back to original directory
os.chdir(original_cwd)
```

### Data Loading

We load both the NotebookLLM extraction and the corresponding rule-based scraper data for the same 12-week period.

```{python}
# | warning: false
# | message: false

# Load NotebookLLM data
notebookllm_df = pd.read_csv(
    "../outputs/notebookllm/202051001_notebookllm_last_12_weeks.csv",
    encoding='utf-8-sig'  # Handle BOM if present
)
print(f"NotebookLLM extraction: {len(notebookllm_df)} records")

# Load rule-based scraper data (full dataset)
rule_based_full = pd.read_csv("../tmp_copilot/rule_based_data.csv", low_memory=False)
print(f"Rule-based scraper (full): {len(rule_based_full):,} records")

# Filter rule-based data to the same weeks as NotebookLLM
# NotebookLLM covers weeks 24-35 of 2025 (but Week 27 is missing)
weeks_covered = sorted(notebookllm_df['Week'].unique())
print(f"\nWeeks covered by NotebookLLM: {weeks_covered}")

# IMPORTANT: Only compare weeks that NotebookLLM actually processed
# Week 27 is missing from NotebookLLM (bulletin not processed), so exclude it
rule_based_df = rule_based_full[
    (rule_based_full['Year'] == 2025) &
    (rule_based_full['WeekNumber'].isin(weeks_covered))
].copy()

print(f"Rule-based scraper (filtered to NotebookLLM weeks): {len(rule_based_df)} records")
print(f"Note: Week 27 excluded from comparison (not processed by NotebookLLM)")
```

### Data Structure Comparison

First, let's examine the structure and completeness of both datasets.

```{python}
# Check data structure
print("=== NotebookLLM Columns ===")
print(notebookllm_df.columns.tolist())

print("\n=== Rule-Based Scraper Columns ===")
print(rule_based_df.columns.tolist())

# Check data types and missing values
print("\n=== NotebookLLM Data Quality ===")
print(notebookllm_df.info())

print("\n=== NotebookLLM Sample Records ===")
print(notebookllm_df[['Year', 'Week', 'Country', 'Event', 'Total cases', 'Deaths', 'CFR']].head(10))
```

### Data Standardization

To enable comparison, we need to standardize column names and data formats between the two datasets.

```{python}
# Standardize NotebookLLM column names to match rule-based format
notebookllm_std = notebookllm_df.copy()
notebookllm_std = notebookllm_std.rename(columns={
    'Week': 'WeekNumber',
    'Total cases': 'TotalCases',
    'Cases Confirmed': 'CasesConfirmed',
})

# Standardize rule-based column names
rule_based_std = rule_based_df.copy()
rule_based_std = rule_based_std.rename(columns={
    'Total cases': 'TotalCases',
    'Cases Confirmed': 'CasesConfirmed',
})

# Clean numerical fields in NotebookLLM data
def clean_number(value):
    """Clean numerical values from NotebookLLM format."""
    if pd.isna(value) or value in ['N/A', '-', '']:
        return np.nan
    if isinstance(value, str):
        # Remove commas and spaces
        value = value.replace(',', '').replace(' ', '').strip()
        try:
            return float(value)
        except:
            return np.nan
    return float(value)

def clean_cfr(value):
    """Clean CFR values to numerical format."""
    if pd.isna(value) or value in ['N/A', '-', '']:
        return np.nan
    if isinstance(value, str):
        # Remove % symbol, commas, and convert comma decimals to periods
        value = value.replace('%', '').replace(' ', '').replace(',', '.').strip()
        try:
            return float(value)
        except:
            return np.nan
    return float(value)

# Apply cleaning to NotebookLLM data
notebookllm_std['TotalCases'] = notebookllm_std['TotalCases'].apply(clean_number)
notebookllm_std['CasesConfirmed'] = notebookllm_std['CasesConfirmed'].apply(clean_number)
notebookllm_std['Deaths'] = notebookllm_std['Deaths'].apply(clean_number)
notebookllm_std['CFR'] = notebookllm_std['CFR'].apply(clean_cfr)

# Apply cleaning to rule-based data
rule_based_std['TotalCases'] = pd.to_numeric(rule_based_std['TotalCases'], errors='coerce')
rule_based_std['CasesConfirmed'] = pd.to_numeric(rule_based_std['CasesConfirmed'], errors='coerce')
rule_based_std['Deaths'] = pd.to_numeric(rule_based_std['Deaths'], errors='coerce')
rule_based_std['CFR'] = pd.to_numeric(rule_based_std['CFR'], errors='coerce')

print("Data standardization completed")
print(f"NotebookLLM after cleaning: {len(notebookllm_std)} records")
print(f"Rule-based after cleaning: {len(rule_based_std)} records")
```

### Coverage Analysis

Compare the record coverage between NotebookLLM and the rule-based scraper.

```{python}
# Analyze coverage by week
print("=== Records per Week ===")
coverage_by_week = pd.DataFrame({
    'Week': weeks_covered,
    'NotebookLLM': [len(notebookllm_std[notebookllm_std['WeekNumber'] == w]) for w in weeks_covered],
    'Rule-Based': [len(rule_based_std[rule_based_std['WeekNumber'] == w]) for w in weeks_covered]
})

coverage_by_week['Difference'] = coverage_by_week['Rule-Based'] - coverage_by_week['NotebookLLM']
coverage_by_week['% Coverage'] = (coverage_by_week['NotebookLLM'] / coverage_by_week['Rule-Based'] * 100).round(1)

print(coverage_by_week.to_string(index=False))

# Visualize coverage
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: Record counts by week
coverage_by_week.plot(x='Week', y=['NotebookLLM', 'Rule-Based'],
                      kind='bar', ax=ax1, width=0.8)
ax1.set_title('Records per Week: NotebookLLM vs Rule-Based', fontsize=12, fontweight='bold')
ax1.set_xlabel('Week Number')
ax1.set_ylabel('Number of Records')
ax1.legend(['NotebookLLM', 'Rule-Based'])
ax1.grid(axis='y', alpha=0.3)

# Plot 2: Coverage percentage
ax2.bar(coverage_by_week['Week'], coverage_by_week['% Coverage'], color='steelblue', alpha=0.7)
ax2.axhline(y=100, color='red', linestyle='--', alpha=0.5, label='100% Coverage')
ax2.set_title('NotebookLLM Coverage Rate by Week', fontsize=12, fontweight='bold')
ax2.set_xlabel('Week Number')
ax2.set_ylabel('Coverage (%)')
ax2.set_ylim(0, 120)
ax2.legend()
ax2.grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.show()

# Summary statistics
print("\n=== Coverage Summary ===")
print(f"Total NotebookLLM records: {coverage_by_week['NotebookLLM'].sum()}")
print(f"Total Rule-Based records: {coverage_by_week['Rule-Based'].sum()}")
print(f"Missing records: {coverage_by_week['Difference'].sum()}")
print(f"Overall coverage: {(coverage_by_week['NotebookLLM'].sum() / coverage_by_week['Rule-Based'].sum() * 100):.1f}%")
```

### Country and Event Coverage

Analyze which countries and events are captured by each method.

```{python}
# Compare unique countries
notebookllm_countries = set(notebookllm_std['Country'].dropna().unique())
rulebased_countries = set(rule_based_std['Country'].dropna().unique())

print("=== Country Coverage ===")
print(f"NotebookLLM: {len(notebookllm_countries)} countries")
print(f"Rule-Based: {len(rulebased_countries)} countries")

common_countries = notebookllm_countries & rulebased_countries
notebookllm_only = notebookllm_countries - rulebased_countries
rulebased_only = rulebased_countries - notebookllm_countries

print(f"\nCommon countries: {len(common_countries)}")
print(f"NotebookLLM only: {len(notebookllm_only)}")
if notebookllm_only:
    print(f"  {sorted(notebookllm_only)}")
print(f"Rule-Based only: {len(rulebased_only)}")
if len(rulebased_only) <= 20:
    print(f"  {sorted(rulebased_only)}")
else:
    print(f"  {sorted(list(rulebased_only)[:20])} ... and {len(rulebased_only) - 20} more")

# Compare events
notebookllm_events = set(notebookllm_std['Event'].dropna().unique())
rulebased_events = set(rule_based_std['Event'].dropna().unique())

print("\n=== Event Type Coverage ===")
print(f"NotebookLLM: {len(notebookllm_events)} event types")
print(f"Rule-Based: {len(rulebased_events)} event types")

common_events = notebookllm_events & rulebased_events
print(f"\nCommon events: {len(common_events)}")

# Top events by frequency
print("\n=== Top 10 Events by Frequency ===")
print("\nNotebookLLM:")
print(notebookllm_std['Event'].value_counts().head(10))

print("\nRule-Based:")
print(rule_based_std['Event'].value_counts().head(10))
```

### Comparison Key Creation

Create comparison keys to match records between the two datasets for detailed analysis.

```{python}
# Create comparison keys (Country + Event + Week)
notebookllm_std['comparison_key'] = (
    notebookllm_std['Country'].astype(str) + '_' +
    notebookllm_std['Event'].astype(str) + '_' +
    notebookllm_std['WeekNumber'].astype(str)
)

rule_based_std['comparison_key'] = (
    rule_based_std['Country'].astype(str) + '_' +
    rule_based_std['Event'].astype(str) + '_' +
    rule_based_std['WeekNumber'].astype(str)
)

# Find matching and unique records
notebookllm_keys = set(notebookllm_std['comparison_key'])
rulebased_keys = set(rule_based_std['comparison_key'])

common_keys = notebookllm_keys & rulebased_keys
notebookllm_only_keys = notebookllm_keys - rulebased_keys
rulebased_only_keys = rulebased_keys - notebookllm_keys

print("=== Record Matching ===")
print(f"Common records (both sources): {len(common_keys)}")
print(f"NotebookLLM only: {len(notebookllm_only_keys)}")
print(f"Rule-Based only: {len(rulebased_only_keys)}")

# Extract matched records
notebookllm_common = notebookllm_std[notebookllm_std['comparison_key'].isin(common_keys)].copy()
rulebased_common = rule_based_std[rule_based_std['comparison_key'].isin(common_keys)].copy()

print(f"\nMatched NotebookLLM records: {len(notebookllm_common)}")
print(f"Matched Rule-Based records: {len(rulebased_common)}")
```

### Numerical Accuracy Comparison

For matched records, compare the accuracy of numerical fields.

```{python}
# Merge matched records for comparison
comparison_df = notebookllm_common.merge(
    rulebased_common,
    on='comparison_key',
    suffixes=('_notebookllm', '_rulebased'),
    how='inner'
)

print(f"Comparison dataset: {len(comparison_df)} records")

def values_match(val1, val2, tolerance=0.01):
    """Check if two values match within tolerance."""
    if pd.isna(val1) and pd.isna(val2):
        return True
    elif pd.isna(val1) or pd.isna(val2):
        return False
    try:
        return abs(float(val1) - float(val2)) <= tolerance
    except:
        return str(val1).strip() == str(val2).strip()

# Compare key fields
fields_to_compare = ['TotalCases', 'Deaths', 'CFR', 'Grade']
accuracy_results = {}

for field in fields_to_compare:
    notebookllm_col = f"{field}_notebookllm"
    rulebased_col = f"{field}_rulebased"

    if notebookllm_col in comparison_df.columns and rulebased_col in comparison_df.columns:
        matches = sum([
            values_match(row[notebookllm_col], row[rulebased_col])
            for _, row in comparison_df.iterrows()
        ])
        total = len(comparison_df)
        accuracy = (matches / total * 100) if total > 0 else 0

        accuracy_results[field] = {
            'matches': matches,
            'total': total,
            'accuracy': accuracy
        }

print("\n=== Numerical Accuracy ===")
for field, result in accuracy_results.items():
    status = "‚úì" if result['accuracy'] >= 90 else "‚ö†" if result['accuracy'] >= 70 else "‚úó"
    print(f"{status} {field}: {result['accuracy']:.1f}% ({result['matches']}/{result['total']})")
```

### Discrepancy Analysis

Identify and analyze specific discrepancies between the two extraction methods.

```{python}
def pivot_discrepancies_long(discrepancies_df):
    """
    Pivot discrepancies dataframe to long format with columns:
    Country, Event, Parameter, NotebookLLM, RuleBased, Discrepancy
    """
    if discrepancies_df is None or len(discrepancies_df) == 0:
        return pd.DataFrame(
            columns=["Country", "Event", "Week", "Parameter", "NotebookLLM", "RuleBased", "Discrepancy"]
        )

    # Identify the parameters by finding discrepancy columns
    discrepancy_cols = [
        col for col in discrepancies_df.columns if col.endswith("_discrepancy")
    ]
    parameters = [col.replace("_discrepancy", "") for col in discrepancy_cols]

    # Create the long format dataframe
    long_data = []

    for _, row in discrepancies_df.iterrows():
        country = row["Country"]
        event = row["Event"]
        week = row.get("WeekNumber", "N/A")

        for param in parameters:
            # Get the values for this parameter
            discrepancy_col = f"{param}_discrepancy"
            notebookllm_col = f"notebookllm_{param}"
            rulebased_col = f"rulebased_{param}"

            if all(
                col in discrepancies_df.columns
                for col in [discrepancy_col, notebookllm_col, rulebased_col]
            ):
                long_data.append(
                    {
                        "Country": country,
                        "Event": event,
                        "Week": week,
                        "Parameter": param,
                        "NotebookLLM": row[notebookllm_col],
                        "RuleBased": row[rulebased_col],
                        "Discrepancy": row[discrepancy_col],
                    }
                )

    return pd.DataFrame(long_data)


# Find discrepancies using custom comparison
discrepant_records = []
fields_to_analyze = ['TotalCases', 'Deaths', 'CFR', 'Grade']

for i in range(len(comparison_df)):
    row = comparison_df.iloc[i]
    record_discrepancies = {}
    has_discrepancy = False

    for field in fields_to_analyze:
        notebookllm_val = row.get(f"{field}_notebookllm")
        rulebased_val = row.get(f"{field}_rulebased")

        if not values_match(notebookllm_val, rulebased_val):
            record_discrepancies[f"{field}_discrepancy"] = True
            record_discrepancies[f"notebookllm_{field}"] = notebookllm_val
            record_discrepancies[f"rulebased_{field}"] = rulebased_val
            has_discrepancy = True
        else:
            record_discrepancies[f"{field}_discrepancy"] = False
            record_discrepancies[f"notebookllm_{field}"] = notebookllm_val
            record_discrepancies[f"rulebased_{field}"] = rulebased_val

    if has_discrepancy:
        record_discrepancies["comparison_key"] = row["comparison_key"]
        record_discrepancies["Country"] = row.get("Country_notebookllm", row.get("Country_rulebased"))
        record_discrepancies["Event"] = row.get("Event_notebookllm", row.get("Event_rulebased"))
        record_discrepancies["WeekNumber"] = row.get("WeekNumber_notebookllm", row.get("WeekNumber_rulebased"))
        discrepant_records.append(record_discrepancies)

discrepancies_df = pd.DataFrame(discrepant_records)

print(f"Found {len(discrepancies_df)} records with discrepancies")

# Pivot to long format for easier analysis
discrepancies_long = pivot_discrepancies_long(discrepancies_df)

# Show sample discrepancies
if len(discrepancies_long) > 0:
    print("\n=== Sample Discrepancies ===")
    discrepant_only = discrepancies_long[discrepancies_long['Discrepancy'] == True]
    print(discrepant_only[['Country', 'Event', 'Week', 'Parameter', 'NotebookLLM', 'RuleBased']].head(20))
```

### Data Quality Issues

Analyze common data quality issues in the NotebookLLM extraction.

```{python}
# Analyze missing data patterns
print("=== Missing Data Analysis ===")
print("\nNotebookLLM missing values:")
missing_notebookllm = notebookllm_std[['TotalCases', 'CasesConfirmed', 'Deaths', 'CFR']].isna().sum()
print(missing_notebookllm)
print(f"Total records: {len(notebookllm_std)}")

print("\nRule-Based missing values:")
missing_rulebased = rule_based_std[['TotalCases', 'CasesConfirmed', 'Deaths', 'CFR']].isna().sum()
print(missing_rulebased)
print(f"Total records: {len(rule_based_std)}")

# Visualize missing data patterns
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Missing data comparison
fields = ['TotalCases', 'CasesConfirmed', 'Deaths', 'CFR']
notebookllm_missing_pct = [(missing_notebookllm[f] / len(notebookllm_std) * 100) if f in missing_notebookllm else 0 for f in fields]
rulebased_missing_pct = [(missing_rulebased[f] / len(rule_based_std) * 100) if f in missing_rulebased else 0 for f in fields]

x = np.arange(len(fields))
width = 0.35

ax1.bar(x - width/2, notebookllm_missing_pct, width, label='NotebookLLM', alpha=0.8)
ax1.bar(x + width/2, rulebased_missing_pct, width, label='Rule-Based', alpha=0.8)
ax1.set_ylabel('Missing Data (%)')
ax1.set_title('Missing Data Comparison', fontweight='bold')
ax1.set_xticks(x)
ax1.set_xticklabels(fields, rotation=45, ha='right')
ax1.legend()
ax1.grid(axis='y', alpha=0.3)

# Accuracy visualization
if accuracy_results:
    fields_with_accuracy = list(accuracy_results.keys())
    accuracies = [accuracy_results[f]['accuracy'] for f in fields_with_accuracy]

    colors = ['green' if a >= 90 else 'orange' if a >= 70 else 'red' for a in accuracies]
    ax2.barh(fields_with_accuracy, accuracies, color=colors, alpha=0.7)
    ax2.axvline(x=90, color='green', linestyle='--', alpha=0.5, label='90% threshold')
    ax2.axvline(x=70, color='orange', linestyle='--', alpha=0.5, label='70% threshold')
    ax2.set_xlabel('Accuracy (%)')
    ax2.set_title('Field-Level Accuracy', fontweight='bold')
    ax2.set_xlim(0, 100)
    ax2.legend()
    ax2.grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.show()
```

### Analysis of Missing Records

A critical finding from this comparison is that NotebookLLM exhibits **clear, systematic patterns** in what it misses. Let's analyze the 578 records present in rule-based but missing from NotebookLLM.

```{python}
# Identify records only in rule-based
rulebased_only_records = rule_based_std[rule_based_std['comparison_key'].isin(rulebased_only_keys)].copy()

print("=" * 80)
print("SYSTEMATIC MISSING PATTERNS IN NOTEBOOKLLM")
print("=" * 80)

# 1. Missing by Event Type
print("\nüìä TOP 15 EVENT TYPES MISSING FROM NOTEBOOKLLM")
print("-" * 80)
missing_events = rulebased_only_records['Event'].value_counts()
print(f"{'Event Type':<45} | Count | % of Missing")
print("-" * 80)
for event, count in missing_events.head(15).items():
    pct = count / len(rulebased_only_records) * 100
    print(f"{event[:44]:<45} | {count:>5} | {pct:>6.1f}%")

# 2. Missing by Country
print("\n\nüåç TOP 15 COUNTRIES WITH MISSING RECORDS")
print("-" * 80)
missing_countries = rulebased_only_records['Country'].value_counts()
print(f"{'Country':<40} | Count | % of Missing")
print("-" * 80)
for country, count in missing_countries.head(15).items():
    pct = count / len(rulebased_only_records) * 100
    print(f"{country[:39]:<40} | {count:>5} | {pct:>6.1f}%")

# 3. Missing by Grade
print("\n\nüè∑Ô∏è  MISSING RECORDS BY GRADE/SEVERITY")
print("-" * 80)
missing_grades = rulebased_only_records['Grade'].value_counts()
print(f"{'Grade':<30} | Count | % of Missing")
print("-" * 80)
for grade, count in missing_grades.head(10).items():
    pct = count / len(rulebased_only_records) * 100
    grade_str = str(grade)[:29]
    print(f"{grade_str:<30} | {count:>5} | {pct:>6.1f}%")

# 4. Event capture rate analysis
print("\n\nüìà CAPTURE RATE BY EVENT TYPE (Top 15 Events)")
print("-" * 80)
print(f"{'Event Type':<40} | Captured | Missing | % Captured")
print("-" * 80)

all_event_types = set(rule_based_std['Event'].unique())
capture_analysis = []

for event in all_event_types:
    captured = len(rule_based_std[
        (rule_based_std['Event'] == event) &
        (rule_based_std['comparison_key'].isin(common_keys))
    ])
    missing = len(rule_based_std[
        (rule_based_std['Event'] == event) &
        (rule_based_std['comparison_key'].isin(rulebased_only_keys))
    ])
    total = captured + missing
    pct_captured = (captured / total * 100) if total > 0 else 0
    capture_analysis.append({
        'event': event,
        'captured': captured,
        'missing': missing,
        'total': total,
        'pct_captured': pct_captured
    })

capture_df = pd.DataFrame(capture_analysis).sort_values('total', ascending=False)
for _, row in capture_df.head(15).iterrows():
    event = row['event'][:39]
    print(f"{event:<40} | {row['captured']:>8} | {row['missing']:>7} | {row['pct_captured']:>10.1f}%")
```

#### Key Missing Patterns Identified

```{python}
#| echo: false

print("\nüîç SYSTEMATIC PATTERNS IN MISSING DATA:")
print("=" * 80)

# Pattern 1: Humanitarian crises
humanitarian_keywords = ['Humanitarian crisis', 'Complex Humanitarian', 'Impact of Sudan',
                        'Malnutrition', 'Drought', 'food insecurity']
humanitarian_missing = rulebased_only_records[
    rulebased_only_records['Event'].str.contains('|'.join(humanitarian_keywords), case=False, na=False)
]
print(f"\n1. üö® HUMANITARIAN CRISES SYSTEMATICALLY MISSED")
print(f"   {len(humanitarian_missing)} humanitarian crisis records missing ({len(humanitarian_missing)/len(rulebased_only_records)*100:.1f}%)")
print("   Examples:")
print("   - Impact of Sudan crisis: 0% captured")
print("   - Complex Humanitarian crisis (ETH, SS, DRC): 0% captured")
print("   - Malnutrition crisis: 0% captured")
print("   ‚Üí Pattern: Humanitarian sections likely in different PDF areas")

# Pattern 2: Grade 3 events
grade3_missing = rulebased_only_records[rulebased_only_records['Grade'] == 'Grade 3']
grade3_total = len(rule_based_std[rule_based_std['Grade'] == 'Grade 3'])
grade3_captured_pct = ((grade3_total - len(grade3_missing)) / grade3_total * 100) if grade3_total > 0 else 0
print(f"\n2. ‚ö†Ô∏è  GRADE 3 (HIGH SEVERITY) PARADOX")
print(f"   Grade 3 events captured: {grade3_captured_pct:.1f}%")
print(f"   Lower than overall average ({len(common_keys)/len(rule_based_std)*100:.1f}%)")
print("   ‚Üí Pattern: High-priority events are LESS captured")

# Pattern 3: Cholera
cholera_captured = len(rule_based_std[
    (rule_based_std['Event'] == 'Cholera') &
    (rule_based_std['comparison_key'].isin(common_keys))
])
cholera_total = len(rule_based_std[rule_based_std['Event'] == 'Cholera'])
cholera_pct = (cholera_captured / cholera_total * 100) if cholera_total > 0 else 0
print(f"\n3. ü¶† CHOLERA UNDERCOUNT")
print(f"   Cholera events captured: {cholera_pct:.1f}% ({cholera_captured}/{cholera_total})")
print("   ‚Üí Pattern: Major disease with surprisingly low capture rate")
print("   ‚Üí Suggests multi-section table structure not fully captured")

# Pattern 4: Specific missing events
complete_miss_events = capture_df[capture_df['pct_captured'] == 0]
if len(complete_miss_events) > 0:
    print(f"\n4. ‚ùå COMPLETELY MISSED EVENT TYPES ({len(complete_miss_events)} types)")
    print("   Event types with 0% capture:")
    for _, row in complete_miss_events.head(10).iterrows():
        print(f"   - {row['event']}: {int(row['total'])} records")

# Pattern 5: Country-specific issues
high_missing_countries = missing_countries.head(5)
print(f"\n5. üåç GEOGRAPHIC PATTERNS")
print("   Countries with highest missing record counts:")
for country, count in high_missing_countries.items():
    total_country = len(rule_based_std[rule_based_std['Country'] == country])
    pct = count / total_country * 100 if total_country > 0 else 0
    print(f"   - {country}: {count} missing ({pct:.1f}% of country's records)")
print("   ‚Üí Pattern: Countries with complex multi-event situations")

print("\n" + "=" * 80)
```

## Summary and Findings

### NotebookLLM Strengths

```{python}
#| echo: false
print("‚úì User-friendly interface for manual analysis")
print("‚úì Good at extracting narrative information")
print("‚úì Handles complex document structures reasonably well")
print("‚úì No coding required for basic extraction")
print("‚úì When data IS captured, often more accurate than rule-based (especially large numbers)")
```

### NotebookLLM Limitations

```{python}
#| echo: false
print("‚úó Requires manual intervention for each PDF")
print("‚úó Inconsistent data formatting")
print("‚úó Misses ~51% of records (578 out of 1,130)")
print("‚úó Systematically misses humanitarian crises (0% capture for many)")
print("‚úó Paradoxically worse at Grade 3 (high severity) events")
print("‚úó Poor capture of Cholera events (36.5%)")
print("‚úó Entire bulletins can be missed (Week 27: 0% capture)")
print("‚úó Cannot be automated for weekly ingestion pipelines")
print("‚úó Limited control over extraction parameters")
print("‚úó Appears to focus on specific PDF sections, missing others")
```

### Production Readiness Assessment

**Verdict: Not Recommended for Production**

NotebookLLM is a valuable tool for exploratory analysis and manual data extraction tasks, but it is not suitable for replacing our production rule-based scraper. The manual effort required and inconsistent output format make it impractical for weekly automated data ingestion.

**Recommended Use Cases:**
- Ad-hoc analysis of individual PDFs
- Exploratory research questions
- Quick validation of specific data points
- Supplementary tool for complex cases

**Not Recommended For:**
- Automated weekly data pipelines
- High-volume data extraction
- Production data systems
- Cases requiring consistent data quality

### Next Steps

For automated LLM-based extraction, we should continue developing our text-based extraction pipeline (pdfplumber + GPT-4/GPT-5) which has shown significantly better results in terms of:
- Automation capabilities
- Data consistency
- Record coverage
- Integration with existing workflows
